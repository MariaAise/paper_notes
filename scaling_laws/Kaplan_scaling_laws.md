Kaplan et al., 2020 — Scaling Laws for Neural Language Models
(OpenAI) The original transformer scaling law paper. Read for:

loss ∝ N^−α behaviour

dataset vs model vs compute scaling

early “50% rule” intuition Still required reading.
